{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahanmee/Machine-Learning-Coursework/blob/main/2425450.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5yfkIIAA85T"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enU2TyegBEf_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn import tree\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYcqZlQFBJPU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Machine Learning Dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HB_X9TLB6Sx"
      },
      "source": [
        "## Quick exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebNaYJ9UB3wv"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRVNvP9zCACL"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEaKVkaeCCZp"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-bcmPIXLVAV"
      },
      "outputs": [],
      "source": [
        "#Drop duplicates\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJT8EVBLabv"
      },
      "outputs": [],
      "source": [
        "duplicates = df[df.duplicated()]\n",
        "duplicates.shape\n",
        "#There are no duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M91xqwY8DPQ9"
      },
      "source": [
        "## Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FonXziQUDPzm"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl8jjXsKNUa-"
      },
      "outputs": [],
      "source": [
        "#Fixing TotalCharges\n",
        "if df['TotalCharges'].dtype == 'object': #This checks whether the TotalCharge is stored as an object (String)\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce') #This is used to convert to numeric, turing non-numeric values into NAN\n",
        "    df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median()) #Replace any NAN values with median value\n",
        "else:\n",
        "    print(\"Column 'TotalCharges' is already numeric, skipping conversion.\") #If it is already converted in to numeric, then do need to change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcAtBlIjNaQI"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C9J6fB33DLf"
      },
      "source": [
        "##Visualizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utFI3sYP3IKP"
      },
      "outputs": [],
      "source": [
        "#Distribution Diagram\n",
        "plt.figure(figsize=(4,4)) #Figure size of the plot\n",
        "sns.countplot(data=df, x=\"Churn\") #Count plot for Churn\n",
        "plt.title(\"Churn Class Distribution\") #Title of the plot\n",
        "plt.show() #Display the plot\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"gender\")\n",
        "plt.title(\"Gender Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"Partner\")\n",
        "plt.title(\"Partner Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"Dependents\")\n",
        "plt.title(\"Dependents Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "sns.countplot(data=df, x=\"tenure\")\n",
        "plt.title(\"tenure Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"PhoneService\")\n",
        "plt.title(\"PhoneService Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"MultipleLines\")\n",
        "plt.title(\"MultipleLines Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"InternetService\")\n",
        "plt.title(\"InternetService Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"OnlineSecurity\")\n",
        "plt.title(\"OnlineSecurity Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"OnlineBackup\")\n",
        "plt.title(\"OnlineBackup Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"DeviceProtection\")\n",
        "plt.title(\"DeviceProtection Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"TechSupport\")\n",
        "plt.title(\"TechSupport Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"StreamingTV\")\n",
        "plt.title(\"StreamingTV Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"StreamingMovies\")\n",
        "plt.title(\"StreamingMovies Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"Contract\")\n",
        "plt.title(\"Contract Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.countplot(data=df, x=\"PaperlessBilling\")\n",
        "plt.title(\"PaperlessBilling Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.countplot(data=df, x=\"PaymentMethod\")\n",
        "plt.title(\"PaymentMethod Class Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.histplot(data=df, x=\"MonthlyCharges\")\n",
        "plt.title(\"Monthly Charges Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.histplot(data=df, x=\"TotalCharges\")\n",
        "plt.title(\"Total Charges Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sHWhxMk3wZl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8)) #Figure size of the heatmap\n",
        "#Select only numeric columns\n",
        "#compute the correlation matrix, and plot it as heatmap\n",
        "#'annot=True' displayes the correlation values inside each cell\n",
        "#'cmap=\"coolwarm\"' sets the color scheme from blue (negative) to red (positive)\n",
        "sns.heatmap(df.select_dtypes(include=[\"int64\", \"float64\"]).corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\") #Title of the heatmap\n",
        "plt.show() #Displays the heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnSLru_x4M_t"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,5)) #Figure size of the boxplot\n",
        "#Create a boxplot to compare the distribution of MonthlyCharges betweeen Churn catergories (Yes/No)\n",
        "#This helps visualize whetehr churners tend to have higher or lower monthly charges\n",
        "sns.boxplot(data=df, y=\"Churn\", x=\"MonthlyCharges\")\n",
        "plt.title(\"Monthly Charges vs Churn\") #Title of the boxplot\n",
        "plt.show() #Display the boxplot\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.boxplot(data=df, y=\"Churn\", x=\"tenure\")\n",
        "plt.title(\"tenure vs Churn\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.boxplot(data=df, y=\"Churn\", x=\"TotalCharges\")\n",
        "plt.title(\"Total Charges vs Churn\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RhBhgXQWqZl"
      },
      "source": [
        "#Removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function calculates the lower and upper bounds using IQR, checks for outliers outside these bounds, and removes them from the dataset.\n",
        "#in the boxplot, showfliers=False is used to hide points near the Range Line that may viually appear as outliers, makinng the plot cleaner."
      ],
      "metadata": {
        "id": "hQbpvR8ib5iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7LI-qYTWlhb"
      },
      "outputs": [],
      "source": [
        "#Define an IQR-based outlier removal function\n",
        "#Q1 and Q3 are calculated for the column\n",
        "#IQR = Q3 - Q1 is used to define the \"normal\" data range\n",
        "#Lower bound = Q1 - 1.5*IQR, Upper bound = Q3 + 1.5*IQR\n",
        "#Any values outside this range are considered outliers and removed\n",
        "\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25) #This calculates the 25th percentile Q1 of the selected column\n",
        "    Q3 = df[column].quantile(0.75) #This calculates the 75th percentile Q3\n",
        "    IQR = Q3 - Q1 #This calculates the IQR\n",
        "    lower_bound = Q1 - 1.5 * IQR #This calculates the lower bound\n",
        "    upper_bound = Q3 + 1.5 * IQR #This calculates the upper bound\n",
        "    print(\"Lower bound:\", lower_bound) #Prints the calculated lower bound\n",
        "    print(\"Upper bound:\", upper_bound) #Prints the calculated upper bound\n",
        "    print(\"Min:\", df[column].min(), \"Max:\", df[column].max()) #Prints the minimum and maximum values in the column to compare with the IQR bounds\n",
        "\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)] #Return the dataframe excluding values outside the IQR range (outliers)\n",
        "\n",
        "\n",
        "#Apply this fucntion to tenure and TotalCharges to filter the dataset\n",
        "#This ensures that extreme values fo not distort our analysis or plots.\n",
        "#In this object, the IQR boounds are wide enough that no roes are actually removed, meaning there are no extreme outliers by this standard\n",
        "\n",
        "df_no_outliers = remove_outliers_iqr(df, 'tenure') #First remove outliers from the tenure column\n",
        "df_no_outliers = remove_outliers_iqr(df_no_outliers, 'TotalCharges') #Then remove outliers from the TotalCharges column (applied on the already\n",
        "#filtered dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUmxHlUBYkxU"
      },
      "outputs": [],
      "source": [
        "#Replot the boxplots\n",
        "#This hides any points near the whiskers that may visually appear as outliers\n",
        "#Even though these points are not true outliers, hiding them makes the boxplot cleaner and emphasizes the main distribution\n",
        "\n",
        "plt.figure(figsize=(6,5)) #Figure size of the boxplot\n",
        "#This boxplot is created to show no outliers in the tenure\n",
        "#'showfliers=False' hides remanining outliers visually\n",
        "sns.boxplot(data=df_no_outliers, y=\"Churn\", x=\"tenure\", showfliers=False)\n",
        "plt.title(\"tenure vs Churn (Outliers Removed)\") #Title of the boxplot\n",
        "plt.show() #Displays the boxplot\n",
        "\n",
        "plt.figure(figsize=(6,5)) #Figure size of the boxplot\n",
        "#This boxplot is created to show no outliers in the TotalCharges\n",
        "#'showfliers=False' hides remanining outliers visually\n",
        "sns.boxplot(data=df_no_outliers, y=\"Churn\", x=\"TotalCharges\", showfliers=False)\n",
        "plt.title(\"Total Charges vs Churn (Outliers Removed)\") #Title of the boxplot\n",
        "plt.show() #Displays the boxplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gvfZQ3oQY0s"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTL7RL22Qg2-"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['customerID', 'PaymentMethod'], axis=1)\n",
        "#Removing customerID and PaymentMethod Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSp-59UCRsyO"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj44GksbWIwZ"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Encoder for 'gender'\n",
        "le_gender = preprocessing.LabelEncoder() #Create a LabelEncoder object ofr wncoding caregorical values\n",
        "# Check if the column still contains string values before encoding\n",
        "if df['gender'].dtype == 'object':\n",
        "    le_gender.fit(['Female','Male']) #Fit the encoder with the known categories 'Female' and 'Male'\n",
        "    df['gender'] = le_gender.transform(df['gender']) #Tranform the column into numeric labels\n",
        "    #Female = 0, Male = 1\n",
        "else:\n",
        "    print(\"Column 'gender' is already numeric, skipping encoding.\") #If the column is already numeric, then skip the encoding step\n",
        "\n",
        "# Encoder for 'Partner'\n",
        "le_partner = preprocessing.LabelEncoder()\n",
        "if df['Partner'].dtype == 'object':\n",
        "    le_partner.fit(['Yes','No'])\n",
        "    df['Partner'] = le_partner.transform(df['Partner'])\n",
        "    #Yes = 1, No = 0\n",
        "else:\n",
        "    print(\"Column 'Partner' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'Dependents'\n",
        "le_dependents = preprocessing.LabelEncoder()\n",
        "if df['Dependents'].dtype == 'object':\n",
        "    le_dependents.fit(['Yes','No'])\n",
        "    df['Dependents'] = le_dependents.transform(df['Dependents'])\n",
        "    #Yes = 1, No = 0\n",
        "else:\n",
        "    print(\"Column 'Dependents' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'PhoneService'\n",
        "le_phoneservice = preprocessing.LabelEncoder()\n",
        "if df['PhoneService'].dtype == 'object':\n",
        "    le_phoneservice.fit(['Yes','No'])\n",
        "    df['PhoneService'] = le_phoneservice.transform(df['PhoneService'])\n",
        "    #Yes = 1, No = 0\n",
        "else:\n",
        "    print(\"Column 'PhoneService' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'MultipleLines'\n",
        "le_multiplelines = preprocessing.LabelEncoder()\n",
        "if df['MultipleLines'].dtype == 'object':\n",
        "    le_multiplelines.fit(['Yes','No','No phone service'])\n",
        "    df['MultipleLines'] = le_multiplelines.transform(df['MultipleLines'])\n",
        "    #No phone service = 0, No = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'MultipleLines' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'InternetService'\n",
        "le_internetservice = preprocessing.LabelEncoder()\n",
        "if df['InternetService'].dtype == 'object':\n",
        "    le_internetservice.fit(['DSL','Fiber optic','No'])\n",
        "    df['InternetService'] = le_internetservice.transform(df['InternetService'])\n",
        "    #DSL = 0, Fiber optic = 1, No = 2\n",
        "else:\n",
        "    print(\"Column 'InternetService' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'OnlineSecurity'\n",
        "le_onlinesecurity = preprocessing.LabelEncoder()\n",
        "if df['OnlineSecurity'].dtype == 'object':\n",
        "    le_onlinesecurity.fit(['Yes','No','No internet service'])\n",
        "    df['OnlineSecurity'] = le_onlinesecurity.transform(df['OnlineSecurity'])\n",
        "    #No = 0, No internet service = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'OnlineSecurity' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'OnlineBackup'\n",
        "le_onlinebackup = preprocessing.LabelEncoder()\n",
        "if df['OnlineBackup'].dtype == 'object':\n",
        "    le_onlinebackup.fit(['Yes','No','No internet service'])\n",
        "    df['OnlineBackup'] = le_onlinebackup.transform(df['OnlineBackup'])\n",
        "    #No = 0, No internet service = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'OnlineBackup' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'DeviceProtection'\n",
        "le_deviceprotection = preprocessing.LabelEncoder()\n",
        "if df['DeviceProtection'].dtype == 'object':\n",
        "    le_deviceprotection.fit(['Yes','No','No internet service'])\n",
        "    df['DeviceProtection'] = le_deviceprotection.transform(df['DeviceProtection'])\n",
        "    #No = 0, No internet service = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'DeviceProtection' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'TechSupport'\n",
        "le_techsupport = preprocessing.LabelEncoder()\n",
        "if df['TechSupport'].dtype == 'object':\n",
        "    le_techsupport.fit(['Yes','No','No internet service'])\n",
        "    df['TechSupport'] = le_techsupport.transform(df['TechSupport'])\n",
        "    #No = 0, No internet service = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'TechSupport' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'StreamingTV'\n",
        "le_streamingtv = preprocessing.LabelEncoder()\n",
        "if df['StreamingTV'].dtype == 'object':\n",
        "    le_streamingtv.fit(['Yes','No','No internet service'])\n",
        "    df['StreamingTV'] = le_streamingtv.transform(df['StreamingTV'])\n",
        "    #No = 0, No internet service = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'StreamingTV' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'StreamingMovies'\n",
        "le_streamingmovies = preprocessing.LabelEncoder()\n",
        "if df['StreamingMovies'].dtype == 'object':\n",
        "    le_streamingmovies.fit(['Yes','No','No internet service'])\n",
        "    df['StreamingMovies'] = le_streamingmovies.transform(df['StreamingMovies'])\n",
        "    #No = 0, No internet service = 1, Yes = 2\n",
        "else:\n",
        "    print(\"Column 'StreamingMovies' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'Contract'\n",
        "le_contract = preprocessing.LabelEncoder()\n",
        "if df['Contract'].dtype == 'object':\n",
        "    le_contract.fit(['Month-to-month','One year','Two year'])\n",
        "    df['Contract'] = le_contract.transform(df['Contract'])\n",
        "    #Month-to-month = 0, One year = 1, Two year = 2\n",
        "else:\n",
        "    print(\"Column 'Contract' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'PaperlessBilling'\n",
        "le_paperlessbilling = preprocessing.LabelEncoder()\n",
        "if df['PaperlessBilling'].dtype == 'object':\n",
        "    le_paperlessbilling.fit(['Yes','No'])\n",
        "    df['PaperlessBilling'] = le_paperlessbilling.transform(df['PaperlessBilling'])\n",
        "    #No = 0, Yes = 1\n",
        "else:\n",
        "    print(\"Column 'PaperlessBilling' is already numeric, skipping encoding.\")\n",
        "\n",
        "# Encoder for 'Churn'\n",
        "le_churn = preprocessing.LabelEncoder()\n",
        "if df['Churn'].dtype == 'object':\n",
        "    le_churn.fit(['Yes','No'])\n",
        "    df['Churn'] = le_churn.transform(df['Churn'])\n",
        "    #No = 0, Yes = 1\n",
        "else:\n",
        "    print(\"Column 'Churn' is already numeric, skipping encoding.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFu69K-vWx7J"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr_r0VG15bZm"
      },
      "source": [
        "##**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho82cMRFAdVB"
      },
      "outputs": [],
      "source": [
        "#TenureGroup\n",
        "df['TenureGroup'] = pd.cut(df['tenure'],\n",
        "                           bins=[0, 12, 24, 36, np.inf],\n",
        "                           labels=['0-12', '12-24', '24-36', '36+'])\n",
        "\n",
        "le_TenureGroup = preprocessing.LabelEncoder()\n",
        "df['TenureGroup'] = le_TenureGroup.fit_transform(df['TenureGroup'].astype(str))\n",
        "\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kQMLXziBJDH"
      },
      "outputs": [],
      "source": [
        "#ChargerCategory\n",
        "df['ChargerCategory'] = pd.cut(df['MonthlyCharges'],\n",
        "                               bins=[0, 50, 100, np.inf],\n",
        "                               labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "le_ChargerCategory = preprocessing.LabelEncoder()\n",
        "df['ChargerCategory'] = le_ChargerCategory.fit_transform(df['ChargerCategory'].astype(str))\n",
        "\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkW7ZI43oCye"
      },
      "outputs": [],
      "source": [
        "#Splitting into Training and Testing sets\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc_xm2iFBOuI"
      },
      "outputs": [],
      "source": [
        "#Rechecking Missing Values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwMziCaDBb-_"
      },
      "outputs": [],
      "source": [
        "#Rechecking Duplicate Values\n",
        "duplicates = df[df.duplicated()]\n",
        "duplicates.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-Ioim-tJGr9"
      },
      "outputs": [],
      "source": [
        "#Removing Duplicate Values\n",
        "df = df.drop_duplicates() #Remove exact duplicates first\n",
        "df = df.drop_duplicates(subset=df.columns.difference(['TotalCharges'])) #Remove near-duplicates ignoring 'TotalCharges'\n",
        "df = df.iloc[0:0] #Remove all remaining rows\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtkxrP4AROJF"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOIXP6ZrRQ8v"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15,20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=dt_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Complete fiiting of Grid Search\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "0LJh7U-Koq01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_dt = grid_search.best_estimator_\n",
        "print(tuned_dt)"
      ],
      "metadata": {
        "id": "EUOsC8h0o5MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do predictions on the train set\n",
        "tuned_dt_pred_train = tuned_dt.predict(X_train)"
      ],
      "metadata": {
        "id": "iQJ3hFbop43I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Accuracy of Train\n",
        "print(accuracy_score(y_train, tuned_dt_pred_train))"
      ],
      "metadata": {
        "id": "MumWcDwokDmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do predictions on the test set\n",
        "tuned_dt_pred_test = tuned_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "-HIGd_gSqiT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Accuracy of Test\n",
        "print(accuracy_score(y_test, tuned_dt_pred_test))"
      ],
      "metadata": {
        "id": "pPWN1qEGkBEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification Report"
      ],
      "metadata": {
        "id": "ZOQoK2GnkHM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report for Decision Tree Test:\")\n",
        "print(classification_report(y_test, tuned_dt_pred_test))\n",
        "\n",
        "print(\"Classification Report for Decision Tree Train:\")\n",
        "print(classification_report(y_train, tuned_dt_pred_train))"
      ],
      "metadata": {
        "id": "AGyo_CNskHc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Confusion Matrix"
      ],
      "metadata": {
        "id": "USdFalT8kW9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix for Decision Tree Test:\")\n",
        "print(confusion_matrix(y_test, tuned_dt_pred_test))\n",
        "\n",
        "print(\"Confusion Matrix for Decision Tree Train:\")\n",
        "print(confusion_matrix(y_train, tuned_dt_pred_train))"
      ],
      "metadata": {
        "id": "k7IJfVRLkUvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ROC Curve + AUC"
      ],
      "metadata": {
        "id": "cQJwhboqkdGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict probabilities for the test set\n",
        "#clf.predict_proba(X_test) returns probabilities for both classes (0 and 1)\n",
        "#We take the probability of the positive class (class1)\n",
        "dt_probs = tuned_dt.predict_proba(X_test)\n",
        "dt_probs = dt_probs[:, 1] #probability of class'1'\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, dt_probs) #Compute False Positive Rate(FPR), True Positive Rate (TPR), and thresholds\n",
        "roc_auc = auc(fpr, tpr) #Compute area under the curve (AUC) for ROC\n",
        "\n",
        "plt.figure(figsize=(8, 6)) #Figure size of the ROC curve\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\") #Plot the diagnol line for a random classifier\n",
        "plt.xlim([0.0, 1.0]) #Axis limits\n",
        "plt.ylim([0.0, 1.05]) #Axis limits\n",
        "plt.xlabel('False Positive Rate') #X axis label\n",
        "plt.ylabel('True Positive Rate') #Y axis label\n",
        "plt.title('Decision Tree ROC Curve') #Title of the ROC curve\n",
        "#Legend and grid for better readability\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show() #Displays the ROC curve"
      ],
      "metadata": {
        "id": "HdmGDKTGkcU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Tree Visualization"
      ],
      "metadata": {
        "id": "_NGG5Tk7khQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12)) #Figure size of the Tree\n",
        "#clf: the trained decision tree classifer\n",
        "#filled=Ture: color the nodes based on the predicted class\n",
        "tree.plot_tree(tuned_dt, filled=True)\n",
        "plt.show() #Displays the Tree"
      ],
      "metadata": {
        "id": "jsJM6Glqkhec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSqUJ5WChA5J"
      },
      "source": [
        "# **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeRm2yNig_4L"
      },
      "outputs": [],
      "source": [
        "# Build Neural Network - Model definition function (IMPORTANT CHANGE)\n",
        "def create_model(optimizer='adam'):\n",
        "    \"\"\"Function that creates and returns a fresh Keras model.\n",
        "       This is required because GridSearchCV will clone this estimator.\"\"\"\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "import numpy as np\n",
        "\n",
        "class KerasBinaryClassifier(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"Custom scikit-learn estimator for Keras binary classification models.\"\"\"\n",
        "\n",
        "    def __init__(self, build_fn=create_model, epochs=10, batch_size=32, optimizer='adam', verbose=0):\n",
        "        self.build_fn = build_fn\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.optimizer = optimizer\n",
        "        self.verbose = verbose\n",
        "        self.model_ = None  # Trained model\n",
        "        self.history_ = None  # Training history\n",
        "\n",
        "    def fit(self, X, y, validation_data=None, callbacks=None):\n",
        "        \"\"\"Fit the Keras model to training data.\"\"\"\n",
        "        # Input validation\n",
        "        X, y = check_X_y(X, y)\n",
        "\n",
        "        # Create a fresh model instance\n",
        "        self.model_ = self.build_fn(optimizer=self.optimizer)\n",
        "\n",
        "        # Store class information\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.n_classes_ = len(self.classes_)\n",
        "\n",
        "        # Train the model\n",
        "        self.history_ = self.model_.fit(\n",
        "            X, y,\n",
        "            epochs=self.epochs,\n",
        "            batch_size=self.batch_size,\n",
        "            validation_data=validation_data,\n",
        "            callbacks=callbacks if callbacks else [],\n",
        "            verbose=self.verbose,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make binary predictions (0 or 1).\"\"\"\n",
        "        check_is_fitted(self, ['model_', 'classes_'])\n",
        "        X = check_array(X)\n",
        "\n",
        "        predictions = self.model_.predict(X, verbose=0)\n",
        "        return (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Return probability estimates.\"\"\"\n",
        "        check_is_fitted(self, ['model_', 'classes_'])\n",
        "        X = check_array(X)\n",
        "\n",
        "        proba = self.model_.predict(X, verbose=0)\n",
        "        # For binary classification: return probabilities for both classes\n",
        "        return np.hstack([1 - proba, proba])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"Return the mean accuracy on the given test data and labels.\"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)\n",
        "\n",
        "# Create the custom estimator (REPLACES KerasClassifier)\n",
        "nn_classifier = KerasBinaryClassifier(\n",
        "    build_fn=create_model,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    optimizer='adam',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "param_grid = {'batch_size': [32, 64],\n",
        "              'epochs': [10, 20],\n",
        "              'optimizer': ['adam', 'rmsprop']\n",
        "              }\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=nn_classifier,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "grid_result = grid_search.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "print(\"Best Parameters:\", grid_result.best_params_)\n",
        "print(\"Best Score:\", grid_result.best_score_)\n",
        "\n",
        "# The best estimator from GridSearchCV\n",
        "best_nn_model = grid_result.best_estimator_\n",
        "\n",
        "# Make predictions with the best model\n",
        "nn_probs_test = best_nn_model.predict(X_test)\n",
        "nn_probs_train = best_nn_model.predict(X_train)\n",
        "\n",
        "# Now continue with your accuracy calculations, classification reports, etc.\n",
        "# Use nn_probs_test and nn_probs_train as before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pslVpCbhv6j"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_.model_"
      ],
      "metadata": {
        "id": "4A_EeEp0zuPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6EUTUnFiAn-"
      },
      "outputs": [],
      "source": [
        "#Accuracy of Test\n",
        "nn_probs_test = best_model.predict(X_test)\n",
        "nn_probs_test = (nn_probs_test > 0.5).astype(int)\n",
        "print(accuracy_score(y_test, nn_probs_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr-bD6X5iYIT"
      },
      "outputs": [],
      "source": [
        "#Accuracy of Train\n",
        "nn_probs_train = best_model.predict(X_train)\n",
        "nn_probs_train = (nn_probs_train > 0.5).astype(int)\n",
        "print(accuracy_score(y_train, nn_probs_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgawZ8jpifan"
      },
      "source": [
        "#Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha_LaDLuiiYF"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report for Neural Network Test:\")\n",
        "print(classification_report(y_test, nn_probs_test))\n",
        "\n",
        "print(\"Classification Report for Neural Network Train:\")\n",
        "print(classification_report(y_train, nn_probs_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEZVSaaoin0z"
      },
      "source": [
        "#Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f-2BaPkiq5d"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix for Neural Network Test:\")\n",
        "print(confusion_matrix(y_test, nn_probs_test))\n",
        "\n",
        "print(\"Confusion Matrix for Neural Network Train:\")\n",
        "print(confusion_matrix(y_train, nn_probs_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJFQTWpAiuVj"
      },
      "source": [
        "#ROC Curve + AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guINivPqizAf"
      },
      "outputs": [],
      "source": [
        "fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_test, nn_probs_test)\n",
        "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_nn, tpr_nn, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_nn)\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Neural Network ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJxsU5atp8mq"
      },
      "source": [
        "# **Comparison of Decision Tree Model and Neural Network Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275c9AQWqcUw"
      },
      "source": [
        "#Store results from both model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwugYgdNqbQN"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"Model\": [\"Tuned Descision Tree\",\"Tuned Neural Network\"],\n",
        "\n",
        "    \"Train Accuracy\": [\n",
        "        accuracy_score(y_train, tuned_dt_pred_train),\n",
        "        accuracy_score(y_train, nn_probs_train)\n",
        "    ],\n",
        "\n",
        "    \"Test Accuracy\": [\n",
        "        accuracy_score(y_test, tuned_dt_pred_test),\n",
        "        accuracy_score(y_test, nn_probs_test)\n",
        "    ],\n",
        "\n",
        "    \"AUC\": [\n",
        "        roc_auc,\n",
        "        roc_auc_nn\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Comparison of Decision Tree Model and Neural Network Model:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs3zW-tnv8Ox"
      },
      "source": [
        "#Precision, Recall, F1-Score Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dENsA0TpwFBC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Model': ['Tuned Decision Tree', 'Tuned Neural Network'],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, tuned_dt_pred_test),\n",
        "        precision_score(y_test, nn_probs_test)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, tuned_dt_pred_test),\n",
        "        recall_score(y_test, nn_probs_test)\n",
        "    ],\n",
        "    \"F1-Score\": [\n",
        "        f1_score(y_test, tuned_dt_pred_test),\n",
        "        f1_score(y_test, nn_probs_test)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"Precision, Recall, F1-Score Comparison:\")\n",
        "print(metrics_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTyiGylWxEJK"
      },
      "source": [
        "#Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7tYds38xHAs"
      },
      "outputs": [],
      "source": [
        "#Create a figure with 1 row and 2 columns for side-by-side plots\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "#Plot the confusion matrix for the Decision Tree\n",
        "sns.heatmap(\n",
        "    confusion_matrix(y_test, tuned_dt_pred_test), #Compute confusion matrix\n",
        "    #annot=True - Show the numbers in each cell\n",
        "    #fmt=\"d\" - Format as integers\n",
        "    #cmap=\"Blues\" - Color map\n",
        "    #ax=ax[0] - Plot in the first subplot\n",
        "    annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[0]\n",
        ")\n",
        "\n",
        "ax[0].set_title(\"Decision Tree Confusion Matrix\")\n",
        "ax[0].set_xlabel(\"Predicted\")\n",
        "ax[0].set_ylabel(\"Actual\")\n",
        "\n",
        "#Plot the confusion matrix for the Neural Network\n",
        "sns.heatmap(\n",
        "    confusion_matrix(y_test, nn_probs_test), #Compute confusion matrix\n",
        "    #annot=True - Show the numbers in each cell\n",
        "    #fmt=\"d\" - Format as integers\n",
        "    #cmap=\"Blues\" - Color map\n",
        "    #ax=ax[0] - Plot in the second subplot\n",
        "    annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[1]\n",
        ")\n",
        "\n",
        "ax[1].set_title(\"Neural Network Confusion Matrix\")\n",
        "ax[1].set_xlabel(\"Predicted\")\n",
        "ax[1].set_ylabel(\"Actual\")\n",
        "\n",
        "plt.tight_layout() #Adjust layout to prevent overlapping title/labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y04DogMix26A"
      },
      "source": [
        "#ROC Curve Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CATrJ_qOx70p"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, label=f\"Decision Tree (AUC = {roc_auc:.2f})\")\n",
        "plt.plot(fpr_nn, tpr_nn, label=f\"Neural Network (AUC = {roc_auc_nn:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j7bh2q6hCYrYn5i4aBmGF8Bw_Bd_mSEz",
      "authorship_tag": "ABX9TyOkUrJa8ABBhb+dS7M/v/O4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}